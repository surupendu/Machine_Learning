{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified percentage is: 4.666666666666666 %\n"
     ]
    }
   ],
   "source": [
    "#3 fold cross validation\n",
    "iris_dataset = datasets.load_iris()\n",
    "\n",
    "#Load Data and label\n",
    "iris_data = iris_dataset.data\n",
    "iris_target = iris_dataset.target\n",
    "\n",
    "#Partition Training Data\n",
    "data1 = iris_data[0:10]\n",
    "label1 = iris_target[0:10]\n",
    "\n",
    "data2 = iris_data[10:20]\n",
    "label2 = iris_target[10:20]\n",
    "\n",
    "data3 = iris_data[20:30]\n",
    "label3 = iris_target[20:30]\n",
    "\n",
    "data4 = iris_data[30:40]\n",
    "label4 = iris_target[30:40]\n",
    "\n",
    "data5 = iris_data[40:50]\n",
    "label5 = iris_target[40:50]\n",
    "\n",
    "data6 = iris_data[50:60]\n",
    "label6 = iris_target[50:60]\n",
    "\n",
    "data7 = iris_data[60:70]\n",
    "label7 = iris_target[60:70]\n",
    "\n",
    "data8 = iris_data[70:80]\n",
    "label8 = iris_target[70:80]\n",
    "\n",
    "data9 = iris_data[80:90]\n",
    "label9 = iris_target[80:90]\n",
    "\n",
    "data10 = iris_data[90:100]\n",
    "label10 = iris_target[90:100]\n",
    "\n",
    "data11 = iris_data[100:110]\n",
    "label11 = iris_target[100:110]\n",
    "\n",
    "data12 = iris_data[110:120]\n",
    "label12 = iris_target[110:120]\n",
    "\n",
    "data13 = iris_data[120:130]\n",
    "label13 = iris_target[120:130]\n",
    "\n",
    "data14 = iris_data[130:140]\n",
    "label14 = iris_target[130:140]\n",
    "\n",
    "data15 = iris_data[140:150]\n",
    "label15 = iris_target[140:150]\n",
    "\n",
    "#End of partition\n",
    "\n",
    "#Create Training and Testing data\n",
    "data_train1 = [data1,data2,data3,data4,data6,data7,data8,data9,data11,data12,data13,data14]\n",
    "label_train1 = [label1,label2,label3,label4,label6,label7,label8,label9,label11,label12,label13,label14]\n",
    "\n",
    "data_train1 = np.reshape(data_train1,(-4,4))\n",
    "label_train1 = np.reshape(label_train1,(-1,1))\n",
    "\n",
    "data_test1 = [data5,data10,data15]\n",
    "label_test1 = [label5,label10,label15]\n",
    "\n",
    "data_test1 = np.reshape(data_test1,(-4,4))\n",
    "label_test1 = np.reshape(label_test1,(-1,1)).ravel()\n",
    "\n",
    "#Calculate Misclassification using Naive Bayes\n",
    "model = GaussianNB()\n",
    "classifier = model.fit(data_train1,label_train1.ravel())\n",
    "predict_label = classifier.predict(data_test1)\n",
    "\n",
    "count1 = 0\n",
    "for i in range(len(predict_label)):\n",
    "    if predict_label[i] != label_test1[i]:\n",
    "        count1 = count1 + 1\n",
    "        \n",
    "avg_count1 = count1/len(data_test1)        \n",
    "\n",
    "\n",
    "#Repeat same logic for rest of the dataset\n",
    "data_train2 = [data2,data3,data4,data5,data7,data8,data9,data10,data12,data13,data14,data15]\n",
    "label_train2 = [label2,label3,label4,label5,label7,label8,label9,label10,label12,label13,label14,label15]\n",
    "\n",
    "data_train2 = np.reshape(data_train2,(-4,4))\n",
    "label_train2 = np.reshape(label_train2,(-1,1))\n",
    "\n",
    "data_test2 = [data1,data6,data11]\n",
    "label_test2 = [label1,label6,label11]\n",
    "\n",
    "data_test2 = np.reshape(data_test2,(-4,4))\n",
    "label_test2 = np.reshape(label_test2,(-1,1)).ravel()\n",
    "\n",
    "classifier = model.fit(data_train2,label_train2.ravel())\n",
    "predict_label = classifier.predict(data_test2)\n",
    "    \n",
    "count2 = 0\n",
    "for i in range(len(predict_label)):\n",
    "    if predict_label[i] != label_test2[i]:\n",
    "        count2 = count2 + 1\n",
    "        \n",
    "avg_count2 = count2/len(data_test2)        \n",
    "\n",
    "\n",
    "data_train3 = [data1,data3,data4,data5,data6,data8,data9,data10,data11,data13,data14,data15]\n",
    "label_train3 = [label1,label3,label4,label5,label6,label8,label9,label10,label11,label13,label14,label15]\n",
    "\n",
    "data_train3 = np.reshape(data_train3,(-4,4))\n",
    "label_train3 = np.reshape(label_train3,(-1,1))\n",
    "\n",
    "data_test3 = [data2,data7,data12]\n",
    "label_test3 = [label2,label7,label12]\n",
    "\n",
    "data_test3 = np.reshape(data_test3,(-4,4))\n",
    "label_test3 = np.reshape(label_test3,(-1,1)).ravel()\n",
    "\n",
    "classifier = model.fit(data_train3,label_train3.ravel())\n",
    "predict_label = classifier.predict(data_test3)\n",
    "    \n",
    "count3 = 0\n",
    "for i in range(len(predict_label)):\n",
    "    if predict_label[i] != label_test3[i]:\n",
    "        count3 = count3 + 1\n",
    "        \n",
    "avg_count3 = count3/len(data_test3)        \n",
    "\n",
    "\n",
    "data_train4 = [data1,data2,data4,data5,data6,data7,data9,data10,data11,data12,data14,data15]\n",
    "label_train4 = [label1,label2,label4,label5,label6,label7,label9,label10,label11,label12,label14,label15]\n",
    "\n",
    "data_train4 = np.reshape(data_train4,(-4,4))\n",
    "label_train4 = np.reshape(label_train4,(-1,1))\n",
    "\n",
    "data_test4 = [data3,data8,data13]\n",
    "label_test4 = [label3,label8,label13]\n",
    "\n",
    "data_test4 = np.reshape(data_test4,(-4,4))\n",
    "label_test4 = np.reshape(label_test4,(-1,1)).ravel()\n",
    "\n",
    "classifier = model.fit(data_train4,label_train4.ravel())\n",
    "predict_label = classifier.predict(data_test4)\n",
    "    \n",
    "count4 = 0\n",
    "for i in range(len(predict_label)):\n",
    "    if predict_label[i] != label_test4[i]:\n",
    "        count4 = count4 + 1\n",
    "        \n",
    "avg_count4 = count4/len(data_test4)\n",
    "        \n",
    "data_train5 = [data1,data2,data3,data5,data6,data7,data8,data10,data11,data12,data13,data15]\n",
    "label_train5 = [label1,label2,label3,label5,label6,label7,label8,label10,label11,label12,label13,label15]\n",
    "\n",
    "data_train5 = np.reshape(data_train5,(-4,4))\n",
    "label_train5 = np.reshape(label_train5,(-1,1))\n",
    "\n",
    "data_test5 = [data4,data9,data14]\n",
    "label_test5 = [label4,label9,label14]\n",
    "\n",
    "data_test5 = np.reshape(data_test5,(-4,4))\n",
    "label_test5 = np.reshape(label_test5,(-1,1)).ravel()\n",
    "\n",
    "classifier = model.fit(data_train5,label_train5.ravel())\n",
    "predict_label = classifier.predict(data_test5)\n",
    "    \n",
    "count5 = 0\n",
    "for i in range(len(predict_label)):\n",
    "    if predict_label[i] != label_test5[i]:\n",
    "        count5 = count5 + 1\n",
    "        \n",
    "avg_count5 = count5/len(data_test5)\n",
    "#End of cross validation\n",
    "\n",
    "\n",
    "print('Misclassified percentage is:',(avg_count1+avg_count2+avg_count3+avg_count4+avg_count5)*100/5,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN using k=1\n",
      "Classified: 99.33333333333334 % Misclassified 0.6666666666666667 %\n",
      "KNN using k=3\n",
      "Classified: 99.33333333333334 % Misclassified 0.6666666666666667 %\n",
      "KNN using k=5\n",
      "Classified: 100.0 % Misclassified 0.0 %\n",
      "KNN using k=11\n",
      "Classified: 100.0 % Misclassified 0.0 %\n"
     ]
    }
   ],
   "source": [
    "#Function to Classify test data using KNN\n",
    "def assign_label(Train_data,Test_data,Train_label,Test_label,k):\n",
    "    \n",
    "    for i in range(len(Test_data)):\n",
    "        NNeighbour = []\n",
    "        New_Label = []\n",
    "        Pick_Label = []\n",
    "        Misclassified = 0\n",
    "        count0,count1,count2 = 0,0,0\n",
    "        for j in range(len(Train_data)):\n",
    "            dist = Train_data[j]-Test_data[i]\n",
    "            NNeighbour = np.insert(NNeighbour,j,np.linalg.norm(dist))  #caluclate euclidean distance\n",
    "        \n",
    "        index = np.argpartition(NNeighbour,k)[:k]            #Obtain k nearest neighbours index\n",
    "        New_Label = Train_label[index]\n",
    "        \n",
    "        #Maintain counts of class 0, class 1, class 2\n",
    "        for j in range(len(New_Label)):\n",
    "            if New_Label[j]==0:\n",
    "                count0 = count0 + 1 \n",
    "            elif New_Label[j]==1:\n",
    "                count1 = count1 + 1\n",
    "            elif New_Label[j]==2:\n",
    "                count2 = count2 + 1\n",
    "        \n",
    "        #Assign label\n",
    "        if count0>count1 and count0>count2:\n",
    "            Pick_Label = 0\n",
    "        elif count1>count0 and count1>count2:\n",
    "            Pick_Label = 1\n",
    "        elif count2>count0 and count2>count1:\n",
    "            Pick_Label = 2\n",
    "                  \n",
    "        if(Test_label[i]!=Pick_Label):\n",
    "            Misclassified = Misclassified + 1\n",
    "    \n",
    "    Misclassified = (Misclassified/len(Test_label))*100\n",
    "    Classified = 100 - Misclassified\n",
    "    return Misclassified,Classified\n",
    "\n",
    "\n",
    "#KNN where k = 1 and using 3 fold cross validation\n",
    "Misclassified1,Classified1 = assign_label(data_train1,data_test1,label_train1.ravel(),label_test1,1)\n",
    "Misclassified2,Classified2 = assign_label(data_train2,data_test2,label_train2.ravel(),label_test2,1)\n",
    "Misclassified3,Classified3 =assign_label(data_train3,data_test3,label_train3.ravel(),label_test3,1)\n",
    "Misclassified4,Classified4 = assign_label(data_train4,data_test4,label_train4.ravel(),label_test4,1)\n",
    "Misclassified5,Classified5 = assign_label(data_train5,data_test5,label_train5.ravel(),label_test5,1)\n",
    "Misclassified = (Misclassified1 + Misclassified2 + Misclassified3 + Misclassified4 + Misclassified5)/5\n",
    "Classified = (Classified1 + Classified2 + Classified3 + Classified4 + Classified5)/5\n",
    "print('KNN using k=1')\n",
    "print('Classified:',Classified,'%','Misclassified',Misclassified,'%')\n",
    "\n",
    "#KNN where k = 3 and using 3 fold cross validation\n",
    "Misclassified1,Classified1 = assign_label(data_train1,data_test1,label_train1.ravel(),label_test1,3)\n",
    "Misclassified2,Classified2 = assign_label(data_train2,data_test2,label_train2.ravel(),label_test2,3)\n",
    "Misclassified3,Classified3 =assign_label(data_train3,data_test3,label_train3.ravel(),label_test3,3)\n",
    "Misclassified4,Classified4 = assign_label(data_train4,data_test4,label_train4.ravel(),label_test4,3)\n",
    "Misclassified5,Classified5 = assign_label(data_train5,data_test5,label_train5.ravel(),label_test5,3)\n",
    "Misclassified = (Misclassified1 + Misclassified2 + Misclassified3 + Misclassified4 + Misclassified5)/5\n",
    "Classified = (Classified1 + Classified2 + Classified3 + Classified4 + Classified5)/5\n",
    "print('KNN using k=3')\n",
    "print('Classified:',Classified,'%','Misclassified',Misclassified,'%')\n",
    "\n",
    "#KNN where k = 5 and using 3 fold cross validation\n",
    "Misclassified1,Classified1 = assign_label(data_train1,data_test1,label_train1.ravel(),label_test1,5)\n",
    "Misclassified2,Classified2 = assign_label(data_train2,data_test2,label_train2.ravel(),label_test2,5)\n",
    "Misclassified3,Classified3 =assign_label(data_train3,data_test3,label_train3.ravel(),label_test3,5)\n",
    "Misclassified4,Classified4 = assign_label(data_train4,data_test4,label_train4.ravel(),label_test4,5)\n",
    "Misclassified5,Classified5 = assign_label(data_train5,data_test5,label_train5.ravel(),label_test5,5)\n",
    "Misclassified = (Misclassified1 + Misclassified2 + Misclassified3 + Misclassified4 + Misclassified5)/5\n",
    "Classified = (Classified1 + Classified2 + Classified3 + Classified4 + Classified5)/5\n",
    "print('KNN using k=5')\n",
    "print('Classified:',Classified,'%','Misclassified',Misclassified,'%')\n",
    "\n",
    "\n",
    "#KNN where k = 11 and using 3 fold cross validation\n",
    "Misclassified1,Classified1 = assign_label(data_train1,data_test1,label_train1.ravel(),label_test1,11)\n",
    "Misclassified2,Classified2 = assign_label(data_train2,data_test2,label_train2.ravel(),label_test2,11)\n",
    "Misclassified3,Classified3 =assign_label(data_train3,data_test3,label_train3.ravel(),label_test3,11)\n",
    "Misclassified4,Classified4 = assign_label(data_train4,data_test4,label_train4.ravel(),label_test4,11)\n",
    "Misclassified5,Classified5 = assign_label(data_train5,data_test5,label_train5.ravel(),label_test5,11)\n",
    "Misclassified = (Misclassified1 + Misclassified2 + Misclassified3 + Misclassified4 + Misclassified5)/5\n",
    "Classified = (Classified1 + Classified2 + Classified3 + Classified4 + Classified5)/5\n",
    "print('KNN using k=11')\n",
    "print('Classified:',Classified,'%','Misclassified',Misclassified,'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
